alt + enter if there's something in red in IntelliJ. 

# Statically VS Dynamic languages
Statically typed language (java, c++, objective c). for all these languages, you have to establish which type of variable you're defining (int n = 2;). Python us a dynamically typed language, like ruby, javascript, etc. 

# to compile java on the terminal. 
javac nameoffile
java nameofclass 

# Java Naming Conventions
Classes are CamelCase
Packages (grouping of classes) are lower.case separated by dots
Methodss & Variables are camelCase
Constants are UPPER_CASE


Fact: When a new array is created. All the "int"s are set to 0. 


# Arrays in JAVA
String[] array = new String[10];
When you create an array, it is fixed. If you want to add range to it, you have to create a new array. You can access easily content in array if we know which element we're looking for. 

int i = array[0];
gets the first element of your array. 

array[0]=1;
sets the first element of the array. 

myLength = array.length;
gets the size of the array. 



ArrayList<String> arrayList = new ArrayList<>();
It's a list that backed by an array. [ArrayList](http://docs.oracle.com/javase/7/docs/api/java/util/ArrayList.html)
They can take care of the resizing of an array and other things.  There is an overhead to using the object ArrayList. If your array is unlikely to change, using a plain array is the way to go. You can create an ArrayList of an array of integers, you need to create another ArrayList of strings, etc. It's just a wrapper for the array, again, allowing you to change it's capacity, etc. 


(Class III - Dec 11)

If you're modeling a game board, you can have multi dimensional arrays. 
int+ [][]
array = new int [5][5];
array[1][1] // to access the array

When might you use an array:
- Order is important
- Data you need to store is fixed-size
- if you need random access, you know the indexes of each item
- a contiguous chunk of memory to iterate through

# Version Control
Styles: server/client type (subversion, perforce, CVS) or distributed type (git, mercurial). 

Keep a stable branch where everything works as expected, do feature work locally (smaller changes) or in a separate branch (big, destructive changes). 

Two models for branching strategy:
- Branch-per-release model: different branch/tag for each release version. 
- Trunk & release branch model: release is prod and trunk is active development. 


# Code Reviews

How are errors handled?
How are variables named?
Are methods/classes too long/complex?
Is it obvious what's happening in the code? 
Can you think of a more elegant/efficient solution to the problem?


# O programming main principles
 
Inheritance: if an object has a parent class, it inherits all of the methods of the parent classes. When looking at a java documentation, the breadcrumbs show which class inherits which. It's useful. 

Polymorphism: treating one thing like another.
when you compare 2 value with ==.When it sees raw strings, it strips them out and creates a global table of strings that exists throughout the timeline of the app and creates one reference for each string that exists. so "dogs" == "dogs" is true while new String("dogs") == new String("dogs") is false because 2 different strings were created. So it's now looking at the objects, not at their content. So then in order to compare the content of two strings, you use the method .equals().
String also has a .equals method. 


Encapsulation: know what you need to know, expose only what you need to expose.
objects are a bundle of functionality. objects should contain only what they need to contain, and only expose what they need to expose. 



result = 3
we start at 2. and go though until n. 
j = 10 ; 

(20-1)+(20*2-10)/2 = 19 + 15


git init
git clone https://github.com/marineb/CSF_Homework.git
git remote add origin https://github.com/marineb/CSF_Homework.git
git remote -v
git remote add upstream https://github.com/generalassembly-studio/CSF_Homework.git
git remote -v
origin	https://github.com/marineb/CSF_Homework.git (fetch)
origin	https://github.com/marineb/CSF_Homework.git (push)
upstream	https://github.com/generalassembly-studio/CSF_Homework.git (fetch)
upstream	https://github.com/generalassembly-studio/CSF_Homework.git (push)


# OOP Vocabulary Review
instances/objects: a bundle of behavior (variables( and states (methods)
method: routine that has access to the state of its object
class: defines the structure and behavior of an object. 

arrayList, Scanner, Random, arrays are all Classes. 

# OOP

- Having public variables can allow anyone to change them. Exposing it can give control to others. 
- We write getters and setters to get and set that data instead. 
- We use "this." to specify that. 

**Encapsulation**
- Getter/setter methods are a general encapsulation best practice. 
- Why isn't everything public?
Stuff changes all the time in code. So you want to reduce the amount of classes you're exposing. So you don't have to change it in too many places when you change one thing in one place. 

The question to ask is: why should this be publicly exposed? Ideally, don't expose. 

In order to set a tiredness level for the dog. Instead of creating an integer within the dog class, it makes more sense to add a variable of the method move(). 

**Object Creation**
- constructors set up an object when it's created (or "instantiated") Dog dog = new Dog();
- Constructors can accept parameters. So for instance when creating an arrayList. Instead of using arrayList(), you use arrayList(int initialCapacity) to set the size you need (instead of having the default size). 
- (Variable can be set on the object outside the constructor, and is expected to be done extremely frequently. )For instance if a dog is always going to have a name. Might as well create the object with the variable in it from the start. For instance:

Dog dog = new Dog("Fido");

instead of 
Dog dog = new Dog();
dog.setName("Fido");

Constructors shouldn't be heavy weight operations. 
In Java, every constructor **must** start with this.

**Inheritance**
>> Inheritance allows you to define child classes for any given class.
>> Parent classes don't know anything about their child classes. 
>> Classes can only have one parent class. 
>> "super." references the superclass method
>> "this." keyword reference the current class

public class Pitbull extends Dog {  
}

This create a sub-class of Dog. 

**Interfaces**
Something's publicly-exposed methods are called its interface. 
Java allows you to bundle together method signatures separately from a class with the interface keyword. Classes can say that they meet that interface by using the "implements" keyword (instead of "extends"). 
The Java interface does not define method implementations, only method signatures. 

Classes can meet different interfaces. 

Unlike class hierarchies, most language allow you to implant multiple interfaces. 

Examples: Map, Collections, List, Queue. 

What is the point of an interface?


**Abstract Classes**
Between an interface and a class. 
Abstract classes define a combination of implementations and 'abstract' methods which must be implemented by subclasses. 

It will force all the subclasses to have that method.  

**Best Practices**
Gather requirements:
 	>> why does my design need to do now?
 	>> what is my design likely to do in the future?
>> start simple and break things out with inheritance and encapsulation as complexity increases
>> an over-designed system can be as painful to deal with as an under-designed one


# polymorphism

Handle different types of objects with a single uniform interface. 

Can take a few forms:
>> a method might accept a superclass as a parameter (Ex object)
>> a method might accept a class that meets an interface as a parameter
>> example: public boolean equals(Object obj) exists on all objects

"Duck"? type programming / system is different. Look into that. 

- subtype polymorphism means that methods do not need to worry about the various implementations of a class. 

public void walkPet (Moveable pet) {  //all that we can call is what's defined in the interface, here MOverable
        System.out.println(pet.move());
    }

The only methods you can call above are the ones that are in the interface.  

Why use polymorphism???
>> accepting the type you need to work on means that those using your class can pass in subclasses, etc, making your methods more versatiles.
>> operate on the most generic type that your method needs to work on

Best practice is always to create new classes based on the highest superclass.


>> careful! imagine this class:hierarchy: Animal > Dog > Chihuahua.     your class has a method which accepts a Dog. 

>> Encapsulation: Know only what you need to know, expose only what you need to expose. 
>> Inheritance: the "is a" relationship.
>> Polyphormism: treating one thing like another. 

Java-isms: _final_ prevents subclasses from overriding a method, _@override_ tells the compiler that you're intending to override a method. 

Interface: a bunch of method signatures. Why use them? You want different classes to have different APIs. 


# Review OO Scope & visibility

**Public, private, protected**
Who can access class variables and methods? 
>> The class
>> Something in the sam package
>> A subclass of the class
>> The rest of the world

IN Java, visibility is restricted with the public, private & protected keywords:
>> public: accessible to everything (and in the case of variable, writeable)
>> protected: accessible by class, subclass & package
>> default (no keyword): accessible by class, package
>> private: accessible only by class

Most OO language support some variation on these levels of visibility, though implementations vary. 

In Java, just prefix your methods/instance variables with these keywords.  

A package is a grouping of classes -- To create a package, use the "package" keyword. 

Use "Final" keyword for constants: variables that can only be assigned once.
private final in offset = 10;

# Scope & Statics
What belongs to an instance, belongs to a class. 

**Instances and Classes**

Instances methods & variables belong to an instance of a class. 
>> Each time you create a new class, it keeps it's own copies of its variables
>> When you change that variable in one class, it doesn't change it in another

Classes methods and variables belong to the class:
>> These are called static methods/variables
>> Accessible & shared by all instances of the class

private static final int offset = 10;
Above, no matter how many instances of this thing are created, the number is never going to be re-assigned a new value. 

When would you use static variables?
>> Constant variables _final_ can safely be static. They're constant so makes sense to share between all instances rather than creating a new copy of the same thing for each. 
>> Utility methods which do not require an instance (e.g.: integer, Character, String conversion method)
>> Singletons (?): single objects that exist in a system (a phone might have a Device class that has a static methods currentDevice(), which returns the current device)
>> Other methods which might conceptually belong to the class of the object
>> Bootstrap methods (e.g.: _public static void main()_)

 Common static pitfalls:
>> You cannot call a method ( _foo();_ ) inside of a static method. In order to do that, you'd have to instantiate a new thing
			X x = new X();
			x.foo();
>> Writeable status state is not a great idea. It's a debugging nightmare. 

Best practices:
>> Static variables should be constant ( _final_ in Java) 
>> Static methods are typically one-off getters/utility methods
>> Avoid sharing writeable state between objects using _static_

# Program Flow & How Objects Are Made

**The Stack & the Heap**

How are objects created?
>> Your programs are loaded into memory when they're running. 
>> Things are stored in memory in 4 buckets:
	>> The stack: roughly a stack of the functions your program is currently executing and their local variables
	>> The Heap: stores instance variable
	>> Statics: static variables for your class
	>> Code: your program's code

[Code]
[Statics]
[Stack]
[Heap]

**The Stack**
>> Every time a method is called, its local variables are pushed onto the stack along with some other data (e.g.: the calling function)
>> Easily visualized in the debugger
>> Stacks are typically fixed-size, small as primitives and object references are very small. That's all they store.


**The Heap** 
>> The heap stores instance variables
>> In Java, any time you call _new_ it creates a new object on the heap 
>> Structure not as well-defined as the stack as objects are constantly created/destroyed in possibly hard to predict patterns
>> Runtimes have complex algorithms for dealing with heap allocation
>> Why segregate memory into the stack & heap? 
			>> For quick access. That stack is super predictable. 
			>> When we compile, we know exactly how much space we'll need. It can organize the stack well. 
			>> We need something to store these objects that live beyond the function, that might be user data. So this stuff can stay around, whereas the stack is for temp data. 
			>> RRRR: at compile time, we know exactly how much memory...... 

**The Stack & The Heap**
Why does it matter?
>> Heap space capped in Java, you can optionally tune/change how much memory is allocated for it
>> Stack space us small and generally fixed; you can run out of it if your stack trace gets too deep ("stack overflow")
>> Not applicable to Java, but in lower-level languages stack buffer overflows exploit behavior of the stack to attack apps ("smashing the stack")


**Exceptions**
>> What happens when the exceptional occurs? Exceptions
>> Exceptions we've seen: INdexOutOfBoundsException, NullPointerException, IllegalArgument...
>> Unchecked Exceptions: are used when the programmer has made an error that isn't detectable at compile-time (null is passed when it shouldn't, you cast an object in a class of which it's not an instance, etc)
>> Checked Exceptions: are used when there is a failure outside the program's control (network failure, padding invalid format, security failure, etc)
>> In java, the former is called an Unchecked exception, and the latter is called a Checked Exception

>> Exception should not be see as part of the normal control flow. They should be used for the exceptional. 
>> Each language has its own exception best practice for when to raise (to throw) and exception which later might be caught
>> Unchecked exceptions are programming errors; they should not be caught
>> Checked exceptions, in Java, can and should be caught. You use try/catch blocks. 
>> You can create new kinds of exceptions by subclassing Exception

public void printFile(String filename) throws FileNotFoundException {
	try {while}
	catch {throw exception}
	finally {}
 }

Best Practices when dealing with exceptions:
>> Throw Exception early, catch late
>> When things go wrong, don't catch, log and re-throw. You program should have one logger. Either log or rethrow, don't do both. 
>> Don't ignore Exceptions
>> Use Exceptions --> email them automatically, etc. 

**Unit Tests & Test-Driven**
>> Tell if the code works before the app runs
>> Java has JUnit, among others
>> Tests are divided into **Test Suites**, which contain **Test Cases** which each have a number of **assertions**
>> testable code tends to be modular, reusable code

**Test-Driven Development**
>> Write test first. Then work on implementation. 
>> Your model classes are great candidates for this. 
>> Tests should be trusted, run, maintained (when a bug is found, update your test)
JUnit uses the @Before (what gets run before test), @test (sequence of test), @After, etc.  

January 6 2013
# Reservation System Homework

Code Review of my homework 
>> if you try to cancel a reservation when none have been created it ends the program
>> more efficient way of iterating over an array

When printing the stuff. Instead of printing each item. Instead, of we added everything in a description at all time, we could always pull the description (it also makes it easier since not all of the reservation systems use all the fields). So you only have one getter instead of all the different getters. 

# OO Design

**Problems of Memory Management**

In C++, every object we create on the heap, we have to create them, and then delete them. It's annoying, you might forget to delete it. Then if you forget, you have this allocated memory that never gets freed up. 

>> "Garbage collection": seeks to automatically delete objects once they're not referenced anymore. 
>> "Reference counting": simpler way to handle memory. anytime some other object references ab object, increment a counter. when the object is dereferenced, decrement the counter. delete counter when it hits 0. 
>> Manually. 

Watch out for circular references (when 2 objects are referenced to each other). They'll never leave. It's a bad performance issue. 

CSS would be smarter if it was like that...! 

**Mark & Sweep**

>> Define a tree of all object references
>> During collection, clear all objects to assume they are unreferenced
>> Walk through the tree, marking objects currently referenced
>> Sweet through the tree, releasing any unmarked objects


Garbage collector will look at every variable in the _stack_ (like foo()). It goes and marks them. This thing is in use, don't delete. For every of these variable, we look at all of their instance variables and see again if they're referenced or not, etc. 
Then we have a new tree of what's in use.   
After it's done that, it goes through the _heap_ and check if anything is in use there. 

The cons is that this Garbage Collection requires that you "stop the world" in order to run. Your application will have to wait. You're scanning through a vast amount of memory to do this.  

Garbage collectors are very complicated (one of the toughest programs to write ever!). 

"Generation Garbage Collection": segments garbage into segments. 

**How Java Does It**

Garbage Collector (GC) cannot be forced. 

finalize() gets called when you're garbage had been collected and is about to get thrown out. 

**How To leak memory in java**
"Memory Leak" when memory isn't freed up, not allocated correctly, etc. 
Holding references you don't need will prevent memory from being freed. 
Don't count just on Garbage Collection. 

**Best Practices**
http://en.wikipedia.org/wiki/SOLID_(object-oriented_design)
No cyclic dependencies! 

Single responsibility: each responsibility should be a separate class. 
Open for extension, closed for modification. classes should strive to be extensible, but not editable, when logic needs to change. 
Liskov substitution. Class X can be swapped for its subclass Y and the programs still valid. 
Interface segregation: depends on the smallest interface possible. 
Dependency inversion: high level modules should not depend on low level modules, they should depend on abstraction. 

- Final: means you can only assign a variable once
- Finally: when you are catching an exception
- Finalize(): see above. 

To minimize garbage, create less objects. 


January 8
# Introduction to ordered data structure (ordered lists)

**Arrays Review**
>> Typically a 1xN, ordered list, can also be multidimensional
>> no easily  resizable
>> operations: get/set at index, create with capacity
>> in java: ArrayList, standard array
ArrayList<String> list = new ArrayList<String>();
String[] list = new String [10];

Use ArrayList when you know exactly how big your list is going to be and not changing. The chess game is a perfect example. 

Or if you know something is always stored in the 1, 20th element, array is a great choice. 

**How do we choose which data structure to use?**
>> What data are we storing? How big will it get?
>> How are we inserting/deleting data?
>> How are we querying data?
>> Other (available memory, etc)


# Complexity Analysis
Introduction to Big-O notation. 

As the size of the problem grows, how does my solution scale?

"Big-O" notation is concerned with worst case. How long does my solution take with worst case situations?

"Big-O" notation ignores constants and things that are fixed. 
http://en.wikipedia.org/wiki/Big_O_notation
Here we're taking the example of a phone book... 

O(1): Constant
ex: access item at an index. 

O(n): Linear. The more the data, the longer it will take. 
ex: search an unsorted array.

O(logn): Logarithmic. Very efficient. Binary search (divide by 2 and pick the side it is going to be, until you find). 
ex: search through a sorted array. 

O(nlogn): All the names are unordered. We need to sort. 
O(n V 2): quadratic. for every name in the phone book, do a linear scan through the phone book to see how many people have the same name. 
O(2 v n): exponential. you have a set of items, each with a weight and a value. find the maximum value combination still under a certain weight. 
 

# Linked Lists

Another ordered data structure. 
What you can do:
>> Insert/remove at beginning/end (o(1))
>> Insert/remove at index n (O(n))
>> Get at beginning/end (O(1))
>> Get at index n (O(n))

When would you use a linked list?
>> Order is important. 
>> Random access is infrequent. 
>> space efficiency is critical
>> Inserts are frequent and the total size of the data is unknown/variable


# Stacks
>> Last in, first out. Always operating on the top. 
>> The stack is an ordered data structure
>> Can be implemented with a  LinkedList
>> Operations: push onto the stack, pop off the stack, peek at the top, get count of items on stack
>> In java: Stack
>> Example use-cases: Stack Trace


firstNode, can be the latest one added. 


# Queues
First in, first out. 
>> The queue is an ordered data structure with a small set of operations
>> Can be implemented with a LinkedList
>> Operations: Enqueue onto the queue, Dequeue off the queue, Peek at the top of the queue, get count of items on queue
>> In Java: LinkedList
>> Example use-cases: Message queue, operation queues. 

// QUESTION: database vs storing data in linked lists, etc. 

Lesson 8 - Jan 13
**Advanced Data Structures: trees and tree traversals**

Java doesn't have a great tree implementation -- some open source stuff can be found. 

A binary tree has from 0 to 2 child nodes on each branch. 
Leaf nodes have no children. 
Trees have a notion of height. Based depth to get to leaf node.

# What is a tree and when are they used?
>> like linked lists, trees are made pup of nodes which contain values
>> Binary search tree allows to search faster. The left value is always smaller than the right value. It's still the idea of looking through a phone book and splitting it in two. Traditionally binary search tree: left is always the smaller value, right is the bigger value. 
>> 

// QUESTION: are trees every used as table like a database? What other type of data do you store in a tree?

# The binary search tree (BST)
>> Great at dynamically sized data set
>> Complexity: insert, query, remove are O(long), Space is O(n)
>> When to use them?
>> >> Dynamically size data
>> >> Frequent searches
>> >> Data changes frequently
Trees have order, but there are several ways one can walk through a tree. 

A "Breath first search": goes through level by level, left to right.  

TIP: IntelliJ: option + enter to get options. 


# Tree traversals
alternatives to breadth first, "depth first": 
>> pre-order traversal: node, left, right
>> in order traversal:left, node, right
>> post order traversal: left, right, node

in order is the most useful traversal. 

If we try to delete something from the tree that has more that one child, we pick one of the children and replace the thing we want to remove by on of the children. The other child becomes a child of this new parent.

# Heaps and priority queues
Link lists are just a subset of trees. 

*The Problem With Balance*
>> Unbalanced trees can cause inconsistent, hard to predict performance
>> If you have a binary tree and insert values in order, you've essentially created a linked list
>> Several advanced trees have properties that help maintain balance
>> Splay trees rebalance on queries, bringing recently-accessed elements to the top / great when query patterns query the most frequently used elements first
>> Red black trees: all nodes have a color, various rules around node colors that enforce balance (they care about neighbor nodes and child nodes)

These above are fairly complicated algorithms. But they're worth it. 

And finally B-trees:
>> exploits properties of a binary tree while generalizing it to have more than 2 children nodes
>> all leaf nodes must have the same level
>> objective is fast search/insert, which is achieved by minimizing tree height
>> not self-balancing in the same manner as Splay trees or red/black trees
>> frequently used in database, filesystem implementation

B trees have ranges in parent nodes. 


# Heaps and priority queues
Keeping track of high scores, most purchased items, etc. 

A binary heap is a binary tree with several properties. 

Priority queue complexity analysis:
Search (peek is 0(1), space o(n), insert is O(long), remove 0(long). 

The only thing we're doing with these is inserting and de-queuing. We're never searching with priority queue. Only thing you're interested in the highest values. 

>> When you have a never ending stream of scores, and want to print the top 100 
>> you're pathfinding through a maze?
>> you have a constantly-changing queue of messages to send, each of which have different priorities?
>>>> How would you you implement this with a linked list-backed queue?
>>>> how fast would it be to insert? To dequeue?

Property of the heap:
>> Completeness: every items has to be filled, and at the bottom (leaf), has to be filled left to right. 
>> Heap property: every child must be larger than its parent

Insert works by "bubble-up":
>> Insert each new node at the open position
>>  If the node is larger than it's parent, swap them until the parent meets the heap property. 

Min-heaps: smallest on top
Max-heaps: biggest on top

For element at index i:
>> parent index: (i-1)/2
>> left child index: (i*2)+2
>> right-child index: (1*2)+2

The Heap: every node is bigger than its children nodes
[grab more stuff here from the slides]


## Advanced Data Structures: maps, sets & graphs

# Sets
>> collection of unique objects
>> usually out of order
>> values are generally unique. can be implemented with arrays or trees. 
>> Operations: create/read/update/delete and then specific operations: union (A,B)[entire content of both sets], intersection (A,B) [where they overlap], subset (A,B)[]
>> Examples: key/value sets in maps


# Maps

**What is A map and where are they used?**
>> Maps are collections of "keys" and "values".
>> Map data structures let you query, add or remove a value for a unique key. 
If you log into a website, your customer information might be stored in a map where the key is your customer ID/email address
>> Maps are generally unordered
>> Map vocabulary
			>> A key is typically an object, and is unique among the set of keys
			>> A value is typically an object, associated with a key. In most map implementations, a key is associated with one value. 

**Hashmap Basic**
>> in java: TreeMap, HashMap, Hashtable
>> Hashmap/hashtable: array-backed solution
>> Array backed solution need to figure out where to put object in their array. This is done with a hash function. 
>> Array backed solutions can perform operations in O(1), as they use arrays as their backing store


Checkout Luhn Algorithm. 
>> The hash function: A method which takes variable-size input and returns a fixed-size 'hash value'
>> Hashmap hash methods should evenly distribute objects across their buckets. 
>> Writing good hash methods is hard. There are very few situations where you will need to write your own. 
>> HashMaps hash the value, mod the result by the number of buckets, then insert in that position. 

>> What happens when HashMaps get full? The rehash. 
>> Since arrays are the HashMap's backing store, we must deal with resizing. Performance issue. 
>> HashMaps allow you to set a capacity on creation, which can minimize rehashes

QUESTION: where does the real value go?

**Strategies for rehashing** 
>> All at once: create a new array with a bigger capacity, move over everything at once
>> Incremental: when a resize is needed, create a new HashMap with bigger size. As queries/inserts are done, movie data from the old HashMap into the new one. 

**When a HashMap hash function resolves two different objects to the same bucket, it's called a collision. How would you mitigate this?**
>> Open addressing: if you hash to a bucket that is already taken, keep looking through the lost until you find an open spot
>> Chaining: each bucket contains a linked list of keys/value, collisions are resolved by adding the key/value to the linked list
>> Hybrid solution of the above


January 22 2013

# Algorithms. 

Data structures reviews
>> Arrays
>> Binary Search Trees
>> Hash Tables

Big Oh is really important. 
OMEGA(1)  -- to insert anything http://en.wikipedia.org/wiki/Big_O_notation#Big_Omega_notation

**Greedy Algorithms**
Seek to make a locally optimal choice at each stage. Coin example. 
They have:
>> A set of things to choose from
>> A notion of 'the best' among the set
>> A notion of feasibility within the set (what is that??)
>> An end state

Greedy algorithms will usually come up with a solution. But it is usually not the best solution. 
>> They are short-sighted
>> They are also non-recoverable

But...
>> They are frequently simple and fast, which has its own advantages. 

# Memoization

Trading speed for space. 

Fibonnacci number is defined by:
F(n) = F(n-1) + F(n-2)
The first 2 fibonnacci numbers are 0 and 1. The next number is the sum of the previous 2 numbers. Easy. 

We start with the beginning, cache the previously calculated values and then keep calculating stuff. 


# Introducing JavaDoc
That adds comments. 


January 27 2013

# Remembering the Big(O) Notation: 
It takes constant time to insert something into the hash map: O(1) because you:
>> look at the thing you need to insert. 
>> look at the hash index where you need to insert it. 
>> and look at the length of the array.

A good hash function needs to spread things well through the hashmap/hashtable. 

If a BST is perfectly balanced, search through it is: log(n). 

Searching through an unbalanced tree or a linked list, it's O(n). 


# Algorithms, Part II
Today, we'll learn about recursion. 

What is a recursive method?
A thing that calls itself. It's self referential. 

For instance:
Fib(n) = Fib (n-1) + Fib (n-2). 

public void recurse() {
		recurse();
}

This above will crash the program (recurse()). It will keep adding itself to the stack until there's no more room (--> "stack overflow"). 


Always start by defining the base cases in recursive functions. 

Use helper recursive methods to make code prettier [http://web.presby.edu/~phmeeker/classes/pc/CSC242/notes/ch13/Recursion%20Continued.htm]


Recursive with nodes. Start with the bases. 
1. See if node is null. if not, 
2. print the value of the node
3. recursive print left
recursivePrint(n.right)

That's in order traversal (NLR). 
Then pre order traversal (LRN) would be:
1. See if node is null. if not, 
2. recursive print left
3. print the value of the node
4. recursivePrint(n.right)

Then if order is post traversal. 

1. See if node is null. if not, 
2.

# Graphs
Graph data structures can model complex relationships. 
>> One to one: your relationship to your SSN
>> one to many: a mother/father's relationship to their children
>> many to many: grocery stores and the products they carry

Graphs are made up of Nodes and Edges. 
>> nodes represent the values in the graph. 
>> edges represent the connections between nodes
>> multiple ways to store these relationships


Twitter "edges" are "directed" (if I follow you, you don't necessarily follow me). Unlike with Facebook for instance, where they're undirected. 

Graphs can be directed or undirected. 

Trees can be thought of as a special type of directed graph. 

**Edges can optionally store data.**
>> Twitter's notion of follower might not store edge data. 
>> LinkedIn's notion of connection does store edge data

**Weighted VS Unweighted.** You can apply a weight to edges. This will add some length to traverse it. 
>> are some paths (edges) more expensive than others? i.e.: Facebook knows you're closer to some friends, some road have speed limits, etc.

**Simple V.S. Not Simple**
>> A simple graph is undirected and has no duplicate edges, no loops back into itself. 

**Sparse / Dense**
Facebook and Twitter probably very sparse. Even the most popular person on Facebook is unlikely to be friend with all users of Facebook.

In a sparse graph, there are fewer edges between nodes. 

**Cyclic / Acyclic.**
Trees are directed acyclic graphs. There are no loops, only one direction.
With a Cyclic graph, you have to worry about marking each node you've visited. 

**Embedded / Topological** 
embedded graphs have geographic/physical position associated with them. 

**Implicit/Explicit**

**Labeled/Unlabeled**
Facebook friends (nodes) have labels. 


Directed Acyclical Graph: comes up in scheduling problems, where vertices must occur in a specify order. 

# Traversal: breadth first search (BFS)


## Algorithms PART 3
Goals for today. 
- Understand "divide and conquer" approaches, and apply this to searching and sorting. 
- Compare and contrast different searching and sorting techniques. 

# Divide and Conquer
- Split data up and perform some recurrence relation on it (i.e.: searching, sorting). this can make things very fast. 
- Good for parallelizing a problem.

# Binary Search: Divide & Conquer a search problem
- sort an array of data
- split the array in half
- choose the half of your desired value would be in 
- recurse into looking at the halves of that half until you find your value

Binary search is log(n). 

Binary search useful for searching area. Useful on searching on arrays. 
Revise breath first search and depth first search. 
There are many more algorithms to look into. 
- Dijkstra's algorithm for instance. 


# Insertion Sort
- insert each element into an array that holds the sorted values, stepping through each element in the sorted array until you find the right place to insert your new value. 
- 0(n^2)
- horrible performance, but simple and actually not bad for small amounts of data in practice 
- watch it in action http://en.wikipedia.org/wiki/Insertion_sort 
- to insert sort, empty the current location, is it bigger or smaller than the previous value? if smaller, we swap the 2 values. 

# Mergesort
How would you sort a trillion numbers?
- Mergesort
- O(n log n)

To merge 2 sorted arrays together, you step through each index of arrays compare them and the smallest of the 2 becomes the next on the new array. This is O(n). 

Merge sort breaks one array into tiny arrays (of one). Then build from there. By merging single arrays into double, into triples, etc. 

This is a classic "divide & conquer". 

Insertion Sort and Merge Sort are divide and conquer. This allows to sort without having to create a bunch of new arrays. 

# Heapsort
- Build up a priority queue from the input, then pluck off the minimum values from that heap one at a time. 
- O(n log n) As good as you can get, but you need to be able to fit everything in memory. 
- Wikipedia: HeapSort

# Selection Sort

# Quick Sort

# Intro Sort, etc etc. A billion sort algorithms to look up....


monday feb 3 2014
## Design Patterns
- learn the model / view /controller design pattern and when it is applied
- learn and apply other common software design pattern
- check out books about design patterns. 

# Factory Method Pattern
The logic for distribution is contained within the class. You call the factory method which returns a randomly configured vehicle (with the example of a factory that creates new cars, the color is based on random and a set range). There's a method specifically used to create new objects. 

Definition: "Static method on a class that returns a new instance of an object". 

It's different than a constructors and we might want to use this instead of it in the following instances:
- when we don't want to expose the inner workings to the "caller"
- in the case that we have one or multiple types of common configurations for a new object. then you use that in addition to a constructor. it gives more flexibility. 

http://en.wikipedia.org/wiki/Factory_method_pattern

# Singleton Patterns

A singleton is a class that enforces that there's only one instance of an object. 

Example. Mobile app. You want to track analytics of the device. There should only be ONE "device", obviously. Or it could be with "current user" for identity. 

Criteria for using singletons:
- every application that we can imagine will use this class in the exact same way. so a logger for instance. 

the one problem with singletons, they have to be both readable and writeable. this can create crazy collisions (it needs to be accessed by several apps possibly). [remember the best practice that classes should when possible only be readable]. 

There are tons of other design patterns. 

# Abstract Factory

Breaking down the making. You have an abstract factory that creates the vehicle and then you have a concrete factory that creates vehicle that are automatic, then another concrete factory that creates smaller vehicles. etc etc. 

# Composite Pattern
This is a structural design pattern. 

When we want the user of this class to be able to operate on one instance the exact same way as they would operate on a bunch of these things. An example of this is when we're talking about view hierarchy. 

Interface View {
		void draw();
}

Class button implements View {
		void draw() { print('button!")}
}

Class CompositeView implements View {
		List<View> views;
		void add(view v) {...}
		void remove(view v) {...}
		void draw() {
				for (View v in views) {
						v.draw();
				}
		}
}


See example below. Why is this powerful?
You can do:

View v2 = new Button();
View v = new Button();
CompositeView c = new CompositeView();
// we can add these 2 buttons to composite
c.add(v);
c.add(v2);
c.draw();
//then draw will loop through all of its children. 
// we can also do that below instead of c.draw();
CompositeView c2 = new CompositeView();
// another composite view
c2.add(newButton());
c2.add(c); 
// above we're adding the composite to the composite 
// therefore you're adding the first buttons to the second view
// then you draw the second composite view
c2.draw();


# Decorator Pattern
Works similarly to the composite pattern. The decorators replace the composite patterns. The decorators take one component. The implementation looks like this:

Interface View {
		void draw();
}

Class Button {
		void draw() {print('button');}
}

Class BordoredView implements View {
		public BordoredView(view v) {
				this.view v;
		}
		void draw() {
				print('Border');
				this.v.print();
		}
		// because this thing is also a view, it has to define the 
		//	draw method
}

and the code would go as is:
Button v = new Button();
BorderView border = new BorderedView(b);
border.draw();

you might have scroll bars you want to decorate; a whole bunch of other things you might want to decorate with a border.  so you can just reuse this class, to do that. 

These decorators can be stacked. You can pass a border decorator and a highlight color decorator for instance, etc etc. 


# Lazy Initialization
Only incur expensive initialization of an object the first time it is actually used. 
It's widely used for Singletons. 

# Object Pool
You're writing a mobile app. User are jaming on the screen with 10 fingers or something. If every single one of those fingers tap spins up a network request, your phone will crash and die. Even on a computer. If you make a bijilion network request, same result. So we use an object pool. Used a lot of the time when you have hardware bottlenecks that you need to overcome. Say the hardware you have can only handle so many X at one time. 
- create a collection of objects of a fixed or maximum size to use. it's like a queue. 
- objects ar recycled, requests for new objects potentially delayed or denied if the pool is full. 
- useful for objects with high initialization or destruction overhead. 
- example: threads, connections.  

# Command Pattern
This is a behavioral pattern concerned with communication between objects. 

# Iterator Pattern
An iterator encapsulates into a class. see below. Would you that instead of a for loop statement. It's useful because:
- if your array size is shrinking
- we can change the order 


void printArrayList(ArrayList al) {
	Iteraor itr = al.iterator();
	while (itr.hasNext()) {
			Object element = itr.next();
			System.out.println(element+ " ");
	}
}

// this below actually uses the iterator. So it's better than a classic for loop. 
for (Object o: list) {
		System.out.println(o);
}


# Model View Controller Pattern (MVC)

- The model is the logic of the application - its data and the methods that can modify it. "Business logic" lives here. 
- The view is the UI Layer; the code that presents the model to the end user (the html, the css, etc)
- The controllers are the glue. they sit in between the view and the model, taking user input from the view and issuing commands to the model.centralizes all access to the model. 


**Rails** is based on mvc frame work. built on ruby. it has folders where you put your models, controllers and views. It actually looks for them. You want to stick with the MVC architecture. 
All the controller does is root. 
It has some superclasses for your models, views, controllers which all have methods set for them. Inheriting behaviors for them.
A lot of web technology lands itself really well to MVC since a lot of it is HTML/css. 

**iOS** has much fewer conventions in terms of where you put your views, controllers and models (than rails). They have views you can configure in a graphic way, they have view controllers that contain a bunch of different views. and models, if you're sticking with something conventional. models and views are defined using this GUIish construct. in code, what you have to implement are the codes. in iOS, it starts with controllers which, then models, then views. 

**MVC Frameworks** Ruby, Java Spring, Struts, ASP.NET MVC, cakePHP, Backbone.js, and many more. 

**MVC Tradeoffs**
- initial development may take longer but...
- easier to maintain and expand
- visual redesigns easier to do (since view is isolated)
- changes to data schema or storage easy to do (since controller is isolated)
- fewer interdependencies in the codebase
- testing is easier


**First milestone for homework**
complete the stories and tasks we need to do. 


Monday February 10th - Lesson 14

# Concurrency

Today's Objectives
- Write concurrent, multi-threaded code safely
- Apply concurrency design patterns to multi-threaded problems
- Apply judicious use of logging  using log4j
- Test the performance and stress handling of applications using perf4j, JMETER

There can be different stacks if you're running different processes at one time. But the heap, statics and code are shared, there's only one of them:
thread		thread			thread
STACKS		STACK			STACKS
					HEAP
					STATICS
					CODE
-------------------------------ALL OF THIS ABOVE IS THE PROCESS

5 philosophers can either eat or think. Only 5 forks at the table. need a fork in the left hand and the right to eat. 
- if they pick up a left fork at the same time, this is a **deadlock**. they get each other in a state that they can never recover. every body is waiting for each other to act. 

Techniques for no deadlock:
- We could make this non-concurrent
- Introduce timing delays so each don't conflict
- Give philosophers the knowledge of what's happening 
- Give a numeric ordering
- Introduce an indépendant arbitrer that decides when people should eat

## Intro to multi-threaded programming
- Take advantage of multiple CPU or GPU cores
- processes: cannot directly access data from other processes
- threads: have their own stack, share data between threads in the same process. 

Synchronous if we don't advance until the previous method is done. 
Asynchronous starts treads. 

Everything we've been doing up to this point has been synchronous. 

## Concurrency Patterns

- Thread pool: create a pool of re-usable threads and a queue of tasks. 6 threads available to you. As new threads are available you add a new task in them. This makes it easier to manage the complexity. 
- Monitor pattern: Mutexes:  one thread can enter this method at a time. if some other thread comes in, it will block until the other moves. if thread b calls the method, until thread a is done, thread b will wait. synchronized means ply one thread can enter one method at one time. 
- Concurrency bugs suck, to avoid, minimize the amount of shared writable state between concurrent operations. 
- semaphored: ensured only n threads will access a resource at a oven time by keeping count of them. see java.util.concurrent.Semaphore

Volatile Keyword. Keyword hint that says, get multiple threads are going to change this at the same time. 

## Logging
log4j not really related to concurrency stuff. loggers have 3 core objects:
- logger (logger.info etc etc) - instead of system.out.print. 
- layout: the view of the logger
- appender: spits out the log file in the console, sends it via email, throw it on a while. 

Logs are really helpful. Something broke at 5am, you want to be able to backtrack and see what happened. 
Loggers help differentiate between error messages, between everything. 

It's super easy to configure. Definitely want to use it with 

- avoid log spam
- don't misclassify your messages
- rotate old logs off (clear after a week, a month, depends on your app)
- make error types uniquely identifiable
- automatically alert someone when fatals or error occur (most important)

There are lots of tools out there to send you text messages, email based on your logs. 

# Performance testing
perf4j
create an object, run some code, stops the object. 
super easy to use. use it. 

